{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  192M    0  8434    0     0   9094      0  6:10:40 --:--:--  6:10:40  9117\n",
      "  0  192M    0  702k    0     0   388k      0  0:08:28  0:00:01  0:08:27  389k\n",
      "  0  192M    0 1566k    0     0   558k      0  0:05:53  0:00:02  0:05:51  559k\n",
      "  1  192M    1 3440k    0     0   904k      0  0:03:38  0:00:03  0:03:35  905k\n",
      "  2  192M    2 5229k    0     0  1088k      0  0:03:01  0:00:04  0:02:57 1088k\n",
      "  3  192M    3 7295k    0     0  1256k      0  0:02:37  0:00:05  0:02:32 1493k\n",
      "  4  192M    4 9132k    0     0  1341k      0  0:02:27  0:00:06  0:02:21 1685k\n",
      "  5  192M    5 10.0M    0     0  1318k      0  0:02:29  0:00:07  0:02:22 1744k\n",
      "  6  192M    6 12.5M    0     0  1454k      0  0:02:15  0:00:08  0:02:07 1871k\n",
      "  7  192M    7 14.4M    0     0  1514k      0  0:02:10  0:00:09  0:02:01 1924k\n",
      "  9  192M    9 17.5M    0     0  1661k      0  0:01:58  0:00:10  0:01:48 2132k\n",
      " 10  192M   10 20.0M    0     0  1726k      0  0:01:54  0:00:11  0:01:43 2243k\n",
      " 11  192M   11 21.4M    0     0  1715k      0  0:01:55  0:00:12  0:01:43 2335k\n",
      " 12  192M   12 24.4M    0     0  1802k      0  0:01:49  0:00:13  0:01:36 2406k\n",
      " 13  192M   13 25.3M    0     0  1714k      0  0:01:55  0:00:15  0:01:40 2082k\n",
      " 13  192M   13 26.5M    0     0  1720k      0  0:01:54  0:00:15  0:01:39 1847k\n",
      " 14  192M   14 28.7M    0     0  1754k      0  0:01:52  0:00:16  0:01:36 1820k\n",
      " 15  192M   15 29.8M    0     0  1711k      0  0:01:55  0:00:17  0:01:38 1700k\n",
      " 17  192M   17 32.9M    0     0  1786k      0  0:01:50  0:00:18  0:01:32 1739k\n",
      " 18  192M   18 35.3M    0     0  1826k      0  0:01:48  0:00:19  0:01:29 2190k\n",
      " 19  192M   19 38.0M    0     0  1873k      0  0:01:45  0:00:20  0:01:25 2358k\n",
      " 21  192M   21 41.1M    0     0  1905k      0  0:01:43  0:00:22  0:01:21 2387k\n",
      " 22  192M   22 42.5M    0     0  1910k      0  0:01:43  0:00:22  0:01:21 2629k\n",
      " 23  192M   23 45.2M    0     0  1946k      0  0:01:41  0:00:23  0:01:18 2560k\n",
      " 24  192M   24 47.7M    0     0  1971k      0  0:01:40  0:00:24  0:01:16 2543k\n",
      " 26  192M   26 50.7M    0     0  2013k      0  0:01:38  0:00:25  0:01:13 2595k\n",
      " 26  192M   26 51.5M    0     0  1969k      0  0:01:40  0:00:26  0:01:14 2266k\n",
      " 27  192M   27 53.0M    0     0  1944k      0  0:01:41  0:00:27  0:01:14 2091k\n",
      " 28  192M   28 55.2M    0     0  1963k      0  0:01:40  0:00:28  0:01:12 2047k\n",
      " 30  192M   30 58.4M    0     0  2009k      0  0:01:38  0:00:29  0:01:09 2197k\n",
      " 32  192M   32 61.9M    0     0  2059k      0  0:01:35  0:00:30  0:01:05 2299k\n",
      " 33  192M   33 64.1M    0     0  2064k      0  0:01:35  0:00:31  0:01:04 2576k\n",
      " 34  192M   34 66.2M    0     0  2068k      0  0:01:35  0:00:32  0:01:03 2784k\n",
      " 36  192M   36 69.7M    0     0  2112k      0  0:01:33  0:00:33  0:01:00 2972k\n",
      " 36  192M   36 71.1M    0     0  2093k      0  0:01:34  0:00:34  0:01:00 2594k\n",
      " 37  192M   37 72.6M    0     0  2047k      0  0:01:36  0:00:36  0:01:00 1980k\n",
      " 37  192M   37 73.2M    0     0  2001k      0  0:01:38  0:00:37  0:01:01 1649k\n",
      " 38  192M   38 73.8M    0     0  2001k      0  0:01:38  0:00:37  0:01:01 1559k\n",
      " 38  192M   38 74.9M    0     0  1966k      0  0:01:40  0:00:39  0:01:01 1025k\n",
      " 39  192M   39 75.7M    0     0  1949k      0  0:01:41  0:00:39  0:01:02  944k\n",
      " 39  192M   39 76.9M    0     0  1927k      0  0:01:42  0:00:40  0:01:02  968k\n",
      " 41  192M   41 79.1M    0     0  1938k      0  0:01:41  0:00:41  0:01:00 1388k\n",
      " 41  192M   41 80.2M    0     0  1903k      0  0:01:43  0:00:43  0:01:00 1217k\n",
      " 42  192M   42 81.9M    0     0  1899k      0  0:01:43  0:00:44  0:00:59 1386k\n",
      " 42  192M   42 82.8M    0     0  1889k      0  0:01:44  0:00:44  0:01:00 1425k\n",
      " 43  192M   43 83.5M    0     0  1867k      0  0:01:45  0:00:45  0:01:00 1367k\n",
      " 43  192M   43 84.1M    0     0  1841k      0  0:01:47  0:00:46  0:01:01 1030k\n",
      " 43  192M   43 84.3M    0     0  1804k      0  0:01:49  0:00:47  0:01:02  884k\n",
      " 44  192M   44 85.2M    0     0  1788k      0  0:01:50  0:00:48  0:01:02  734k\n",
      " 44  192M   44 86.1M    0     0  1770k      0  0:01:51  0:00:49  0:01:02  678k\n",
      " 45  192M   45 87.0M    0     0  1743k      0  0:01:53  0:00:51  0:01:02  675k\n",
      " 45  192M   45 88.4M    0     0  1729k      0  0:01:54  0:00:52  0:01:02  786k\n",
      " 46  192M   46 89.1M    0     0  1721k      0  0:01:54  0:00:53  0:01:01  955k\n",
      " 46  192M   46 90.2M    0     0  1716k      0  0:01:55  0:00:53  0:01:02 1016k\n",
      " 47  192M   47 92.4M    0     0  1725k      0  0:01:54  0:00:54  0:01:00 1283k\n",
      " 48  192M   48 93.3M    0     0  1713k      0  0:01:55  0:00:55  0:01:00 1383k\n",
      " 49  192M   49 94.9M    0     0  1700k      0  0:01:56  0:00:57  0:00:59 1384k\n",
      " 49  192M   49 95.5M    0     0  1672k      0  0:01:58  0:00:58  0:01:00 1201k\n",
      " 49  192M   49 96.1M    0     0  1673k      0  0:01:57  0:00:58  0:00:59 1210k\n",
      " 51  192M   51 98.5M    0     0  1688k      0  0:01:57  0:00:59  0:00:58 1272k\n",
      " 52  192M   52  100M    0     0  1688k      0  0:01:56  0:01:00  0:00:56 1419k\n",
      " 52  192M   52  101M    0     0  1663k      0  0:01:58  0:01:02  0:00:56 1260k\n",
      " 52  192M   52  102M    0     0  1642k      0  0:02:00  0:01:03  0:00:57 1303k\n",
      " 53  192M   53  102M    0     0  1649k      0  0:01:59  0:01:03  0:00:56 1362k\n",
      " 54  192M   54  104M    0     0  1649k      0  0:01:59  0:01:04  0:00:55 1191k\n",
      " 54  192M   54  105M    0     0  1633k      0  0:02:00  0:01:05  0:00:55  962k\n",
      " 55  192M   55  106M    0     0  1627k      0  0:02:01  0:01:06  0:00:55 1128k\n",
      " 55  192M   55  107M    0     0  1626k      0  0:02:01  0:01:07  0:00:54 1378k\n",
      " 57  192M   57  110M    0     0  1638k      0  0:02:00  0:01:08  0:00:52 1502k\n",
      " 58  192M   58  113M    0     0  1657k      0  0:01:59  0:01:09  0:00:50 1759k\n",
      " 59  192M   59  114M    0     0  1645k      0  0:02:00  0:01:11  0:00:49 1785k\n",
      " 60  192M   60  116M    0     0  1662k      0  0:01:58  0:01:11  0:00:47 2138k\n",
      " 60  192M   60  117M    0     0  1652k      0  0:01:59  0:01:12  0:00:47 1998k\n",
      " 61  192M   61  118M    0     0  1647k      0  0:01:59  0:01:13  0:00:46 1767k\n",
      " 62  192M   62  120M    0     0  1648k      0  0:01:59  0:01:15  0:00:44 1529k\n",
      " 62  192M   62  121M    0     0  1636k      0  0:02:00  0:01:15  0:00:45 1517k\n",
      " 63  192M   63  122M    0     0  1636k      0  0:02:00  0:01:16  0:00:44 1259k\n",
      " 64  192M   64  124M    0     0  1634k      0  0:02:00  0:01:17  0:00:43 1369k\n",
      " 65  192M   65  125M    0     0  1629k      0  0:02:01  0:01:18  0:00:43 1364k\n",
      " 65  192M   65  126M    0     0  1623k      0  0:02:01  0:01:19  0:00:42 1224k\n",
      " 66  192M   66  128M    0     0  1622k      0  0:02:01  0:01:20  0:00:41 1401k\n",
      " 67  192M   67  130M    0     0  1627k      0  0:02:01  0:01:21  0:00:40 1484k\n",
      " 68  192M   68  131M    0     0  1630k      0  0:02:01  0:01:22  0:00:39 1571k\n",
      " 69  192M   69  134M    0     0  1635k      0  0:02:00  0:01:24  0:00:36 1727k\n",
      " 70  192M   70  135M    0     0  1627k      0  0:02:01  0:01:25  0:00:36 1692k\n",
      " 71  192M   71  137M    0     0  1635k      0  0:02:00  0:01:25  0:00:35 1848k\n",
      " 72  192M   72  139M    0     0  1646k      0  0:01:59  0:01:26  0:00:33 1968k\n",
      " 73  192M   73  142M    0     0  1657k      0  0:01:59  0:01:27  0:00:32 2099k\n",
      " 75  192M   75  145M    0     0  1673k      0  0:01:58  0:01:29  0:00:29 2335k\n",
      " 76  192M   76  147M    0     0  1683k      0  0:01:57  0:01:29  0:00:28 2672k\n",
      " 78  192M   78  151M    0     0  1704k      0  0:01:55  0:01:30  0:00:25 2887k\n",
      " 80  192M   80  154M    0     0  1728k      0  0:01:54  0:01:31  0:00:23 3148k\n",
      " 82  192M   82  158M    0     0  1746k      0  0:01:53  0:01:32  0:00:21 3327k\n",
      " 82  192M   82  159M    0     0  1736k      0  0:01:53  0:01:34  0:00:19 2801k\n",
      " 83  192M   83  161M    0     0  1738k      0  0:01:53  0:01:35  0:00:18 2687k\n",
      " 84  192M   84  162M    0     0  1739k      0  0:01:53  0:01:35  0:00:18 2376k\n",
      " 85  192M   85  165M    0     0  1746k      0  0:01:53  0:01:37  0:00:16 2070k\n",
      " 86  192M   86  167M    0     0  1750k      0  0:01:52  0:01:37  0:00:15 1830k\n",
      " 86  192M   86  167M    0     0  1732k      0  0:01:54  0:01:39  0:00:15 1651k\n",
      " 87  192M   87  168M    0     0  1726k      0  0:01:54  0:01:39  0:00:15 1484k\n",
      " 87  192M   87  168M    0     0  1713k      0  0:01:55  0:01:40  0:00:15 1204k\n",
      " 87  192M   87  169M    0     0  1702k      0  0:01:56  0:01:41  0:00:15  793k\n",
      " 88  192M   88  170M    0     0  1695k      0  0:01:56  0:01:42  0:00:14  639k\n",
      " 88  192M   88  171M    0     0  1689k      0  0:01:56  0:01:43  0:00:13  782k\n",
      " 89  192M   89  172M    0     0  1685k      0  0:01:57  0:01:44  0:00:13  886k\n",
      " 90  192M   90  174M    0     0  1684k      0  0:01:57  0:01:45  0:00:12 1102k\n",
      " 90  192M   90  175M    0     0  1680k      0  0:01:57  0:01:46  0:00:11 1230k\n",
      " 91  192M   91  177M    0     0  1681k      0  0:01:57  0:01:48  0:00:09 1395k\n",
      " 92  192M   92  178M    0     0  1672k      0  0:01:58  0:01:49  0:00:09 1327k\n",
      " 92  192M   92  178M    0     0  1663k      0  0:01:58  0:01:50  0:00:08 1206k\n",
      " 93  192M   93  179M    0     0  1660k      0  0:01:58  0:01:50  0:00:08 1148k\n",
      " 93  192M   93  180M    0     0  1656k      0  0:01:59  0:01:51  0:00:08 1137k\n",
      " 94  192M   94  182M    0     0  1652k      0  0:01:59  0:01:52  0:00:07  993k\n",
      " 94  192M   94  182M    0     0  1637k      0  0:02:00  0:01:54  0:00:06  928k\n",
      " 95  192M   95  183M    0     0  1639k      0  0:02:00  0:01:54  0:00:06 1100k\n",
      " 96  192M   96  185M    0     0  1637k      0  0:02:00  0:01:56  0:00:04 1146k\n",
      " 97  192M   97  187M    0     0  1637k      0  0:02:00  0:01:57  0:00:03 1234k\n",
      " 97  192M   97  188M    0     0  1628k      0  0:02:01  0:01:58  0:00:03 1162k\n",
      " 98  192M   98  189M    0     0  1629k      0  0:02:01  0:01:58  0:00:03 1425k\n",
      " 98  192M   98  190M    0     0  1625k      0  0:02:01  0:02:00  0:00:01 1310k\n",
      " 99  192M   99  191M    0     0  1626k      0  0:02:01  0:02:00  0:00:01 1362k\n",
      "100  192M  100  192M    0     0  1630k      0  0:02:01  0:02:01 --:--:-- 1442k\n"
     ]
    }
   ],
   "source": [
    "#@title Install Ithaca, download the checkpoint\n",
    "!pip install -q git+https://github.com/MariaSchoinaki/ithaca || echo \"*** FAILED TO INSTALL ITHACA ***\"\n",
    "!curl --output checkpoint.pkl https://storage.googleapis.com/ithaca-resources/models/checkpoint_v1.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "try:\n",
    "  import ithaca\n",
    "  import flax\n",
    "except ModuleNotFoundError:\n",
    "  display(HTML('<h1><font color=\"#f00\">Failed to import ithaca. Did installation fail above?</font></h1>'))\n",
    "  raise\n",
    "\n",
    "import functools\n",
    "\n",
    "from flax import linen as nn\n",
    "import folium\n",
    "import jax\n",
    "import jinja2\n",
    "import matplotlib.pyplot as plt\n",
    "from ml_collections import config_dict\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from ithaca.eval import inference\n",
    "from ithaca.models.model import Model\n",
    "from ithaca.util.alphabet import GreekAlphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configuration and auxiliary functions\n",
    "\n",
    "class dataset_config:\n",
    "  date_interval = 10\n",
    "  date_max = 800\n",
    "  date_min = -800\n",
    "\n",
    "def get_subregion_name(id, region_map):\n",
    "  return region_map['sub']['names_inv'][region_map['sub']['ids_inv'][id]]\n",
    "\n",
    "def bce_ad(d):\n",
    "  if d < 0:\n",
    "    return f'{abs(d)} BCE'\n",
    "  elif d > 0:\n",
    "    return f'{abs(d)} AD'\n",
    "  return 0\n",
    "\n",
    "\n",
    "SALIENCY_SNIPPET_TEMPLATE = jinja2.Template(\"\"\"\n",
    "<div class=\"saliency\">\n",
    "  {% for char, score in pairs -%}\n",
    "    <span\n",
    "      style=\"background-color: rgba(171,71,188,{{'%.2f'|format(score)}});\"\n",
    "      title=\"Saliency score {{'%.2f'|format(score)}}\">{{ char }}</span>\n",
    "  {%- endfor %}\n",
    "</div>\n",
    "\"\"\")\n",
    "\n",
    "SALIENCY_TEMPLATE = jinja2.Template(\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
    "<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400&family=Roboto:wght@400&display=swap\" rel=\"stylesheet\">\n",
    "<style>\n",
    "body { font-family: 'Roboto Mono', monospace; }\n",
    ".saliency {\n",
    "  word-wrap: break-word;\n",
    "  white-space: normal;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "{{body_html|safe}}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def generate_saliency(text, saliency, snippet=False):\n",
    "  \"\"\"Generates saliency visualisation.\"\"\"\n",
    "  snippet_html = SALIENCY_SNIPPET_TEMPLATE.render(\n",
    "      pairs=list(zip(text, saliency)))\n",
    "  if snippet:\n",
    "    return snippet_html\n",
    "  return SALIENCY_TEMPLATE.render(body_html=snippet_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load and create model\n",
    "with open(\"checkpoint.pkl\", \"rb\") as f:\n",
    "  checkpoint = pkl.load(f)\n",
    "\n",
    "model_config = config_dict.ConfigDict(checkpoint['model_config'])\n",
    "params = jax.device_put(checkpoint['params'])\n",
    "\n",
    "alphabet = GreekAlphabet()\n",
    "alphabet.idx2word = checkpoint['alphabet']['idx2word']\n",
    "alphabet.word2idx = checkpoint['alphabet']['word2idx']\n",
    "\n",
    "vocab_char_size = checkpoint['model_config']['vocab_char_size']\n",
    "vocab_word_size = checkpoint['model_config']['vocab_word_size']\n",
    "\n",
    "region_map = checkpoint['region_map']\n",
    "\n",
    "forward = functools.partial(Model(**model_config).apply, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title  { run: \"auto\", vertical-output: true }\n",
    "text = 'βασιλισσης και βασιλεως προσταξαντων αντι της προανακειμενης περι της αναθεσεως της προσευχης πλακος η υπογεγραμμενη επιγραφητω. βασιλευς πτολεμαιος ευεργετης την προσευχην ασυλον.' #@param {type:\"string\"}\n",
    "assert 50 <= len(text) <= 750, \"text should be between 50 and 750 chars long, got \" + str(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Chronological attribution\n",
    "#@markdown Ithaca’s chronological attribution hypotheses, visualized as a categorical distribution over decades, in yellow, between 800 BCE and 800 CE. This visualisation enables the handling of date intervals more effectively and aids the interpretability of the hypotheses.\n",
    "\n",
    "attribution_results = inference.attribute(\n",
    "    text=text,\n",
    "    forward=forward,\n",
    "    params=params,\n",
    "    alphabet=alphabet,\n",
    "    vocab_char_size=vocab_char_size,\n",
    "    vocab_word_size=vocab_word_size,\n",
    "    region_map=region_map\n",
    ")\n",
    "\n",
    "# Compute scores\n",
    "date_pred_y = np.array(attribution_results.year_scores)\n",
    "date_pred_x = np.arange(\n",
    "  dataset_config.date_min + dataset_config.date_interval / 2,\n",
    "  dataset_config.date_max + dataset_config.date_interval / 2,\n",
    "  dataset_config.date_interval)\n",
    "date_pred_argmax = date_pred_y.argmax(\n",
    ") * dataset_config.date_interval + dataset_config.date_min + dataset_config.date_interval // 2\n",
    "date_pred_avg = np.dot(date_pred_y, date_pred_x)\n",
    "\n",
    "# Plot figure\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "plt.bar(date_pred_x, date_pred_y, color='#f2c852', width=10., label='Ithaca distribution')\n",
    "plt.axvline(x=date_pred_avg, color='#67ac5b', linewidth=2., label='Ithaca average')\n",
    "\n",
    "\n",
    "plt.ylabel('Probability', fontsize=14)\n",
    "yticks = np.arange(0, 1.1, 0.1)\n",
    "yticks_str = list(map(lambda x: f'{int(x*100)}%', yticks))\n",
    "plt.yticks(yticks, yticks_str, fontsize=12, rotation=0)\n",
    "plt.ylim(0, int((date_pred_y.max()+0.1)*10)/10)\n",
    "\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "xticks = list(range(dataset_config.date_min, dataset_config.date_max + 1, 25))\n",
    "xticks_str = list(map(bce_ad, xticks))\n",
    "plt.xticks(xticks, xticks_str, fontsize=12, rotation=0)\n",
    "plt.xlim(int(date_pred_avg - 100), int(date_pred_avg + 100))\n",
    "plt.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Chronological attribution saliency map\n",
    "#@markdown Saliency map shows which unique input text features contributed the most to Ithaca’s top chronological attribution hypothesis.\n",
    "display(HTML(generate_saliency(\n",
    "    text=attribution_results.input_text,\n",
    "    saliency=attribution_results.date_saliency)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.util import bigrams\n",
    "import numpy as np\n",
    "\n",
    "# dictionary with 10 texts and target bigrams\n",
    "texts_data = {\n",
    "    \"ID_219963\": {\n",
    "        \"text\": \"βασιλισσης και βασιλεως προσταξαντων αντι της προανακειμενης περι της αναθεσεως της προσευχης πλακος η υπογεγραμμενη επιγραφητω. βασιλευς πτολεμαιος ευεργετης την προσευχην ασυλον.\",\n",
    "        \"target_bigrams\": [(\"βασιλευς\", \"πτολεμαιος\")],\n",
    "    },\n",
    "    \"ID_30483\": {\n",
    "        \"text\": \"βιδεοι επι δαμοκλεους του του και φιλοκρατους ----ρι--τ- το β καλλιμαχος ---κλεους κλεων φιλοστρατος ---ιππου γαιος ιουλιος καλ-τικελω κασεν --------ρατου.\",\n",
    "        \"target_bigrams\": [(\"γαιος\", \"ιουλιος\")],\n",
    "    },\n",
    "    \"ID_28743\": {\n",
    "        \"text\": \"λευκιος μομμιος λευκιου στρατηγος υπατος ρωμαιων απολλωνι ασκληπιωι υγιειαι.\",\n",
    "        \"target_bigrams\": [(\"στρατηγος\", \"υπατος\"), (\"λευκιος\", \"μομμιος\")],\n",
    "    },\n",
    "    \"ID_284303\": {\n",
    "        \"text\": \"τιβεριος κλαυδιος τιβεριου κλαυδιου αγριππεινου υπατου υιος κυρεινα ----- τας εξεδρας τη γλυκυτατη πατριδι ανεθηκεν.\",\n",
    "        \"target_bigrams\": [(\"τιβεριος\", \"κλαυδιος\")],\n",
    "    },\n",
    "    \"ID_208503\": {\n",
    "        \"text\": \"αυτοκρατορα καισαρα μαρκον αυρηλιον σευηρον αντωνεινον ανικητον ευσεβη ευτυχη σεβαστον παρθικον μεγιστον βρεταννικον μεγιστον αρχιερεα μεγιστον δημαρχικης εξουσιας πατερα πατριδος κουριεων η πολις.\",\n",
    "        \"target_bigrams\": [(\"ευσεβη\", \"ευτυχη\")],\n",
    "    },\n",
    "    \"ID_321813\": {\n",
    "        \"text\": \"υριε αναπαυσον ιωαννην αζιζεου. κυριε ο θεος της αγιας μαριας και παντων των αγιων ελεησον παντος του κοσμου και βοηθεσον τους προσφεροντας και ιωαννην αναηλου του ευλαβεστατου διακονου μηνι ξανθικου ινδικτιωνος.\",\n",
    "        \"target_bigrams\": [(\"αγιας\", \"μαριας\")],\n",
    "    },\n",
    "    \"ID_216073\": {\n",
    "        \"text\": \"υπερ βασιλισσα κλεοπατρα και βασιλευς πτολεμαιος θεων φιλομητορων και θεων σωτηρων ηρωδης. ------ και πανις δε-----------π--.\",\n",
    "        \"target_bigrams\": [(\"βασιλισσα\", \"κλεοπατρα\"), (\"βασιλευς\", \"πτολεμαιος\")],\n",
    "    },\n",
    "    \"ID_237533\": {\n",
    "        \"text\": \"βασιλευς αντιοχος φιλοπαππος βασιλεως επιφανους του αντιοχου. βασιλευς αντιοχος βασιλεως αντιοχου. φιλοπαππος επιφανους βησαιευς. βασιλευς σελευκος αντιοχου νικατωρ.\",\n",
    "        \"target_bigrams\": [(\"βασιλευς\", \"σελευκος\"), (\"βασιλευς\", \"αντιοχος\")],\n",
    "    },\n",
    "    \"ID_342423\": {\n",
    "        \"text\": \"μαρκος αυρηλιος μακεδων κατεσκευασα τον ταφον εμαυτω και βουλομαι ενταφηναι μετα την αποβιωσιν αλλον δε μηδενα ενεστιν η προμαμμην ------------ ενταφηναι και την γυναικα μου αυρηλιαν ο-----ολι δε μηδενα επει ο τολμησας υποκεισεται τω ιερωτατω ταμειω.\",\n",
    "        \"target_bigrams\": [(\"αρκος\", \"αυρηλιος\"), (\"μαρκος\", \"αυρηλιος\")],\n",
    "    },\n",
    "    \"ID_242543\": {\n",
    "        \"text\": \"διι μαδβαχω και σελαμανει πατρωοις ευχην γαιος ουαλεριος προκλος και συμαχος των δειοκλους αμα των υων αυτων οικοδομησαντες εν τω ανατολικω μερι του περιβολου και μεσηνβρινην γωνιαν εκ των ιδιων εκτισαν δραχων α οικοδομησαν πηχεις μηκους μεν κ υψους δε πηχεις δια ----.\",\n",
    "        \"target_bigrams\": [(\"γαιος\", \"ουαλεριος\")],\n",
    "    },\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Function to find bigram indices in the text\n",
    "def find_bigram_indices(text, target_bigram):\n",
    "    tokens = text.split()\n",
    "    text_bigrams = [(tokens[i], tokens[i + 1]) for i in range(len(tokens) - 1)]\n",
    "\n",
    "    try:\n",
    "        bigram_index = text_bigrams.index(target_bigram)\n",
    "        start_idx = sum(len(tokens[i]) + 1 for i in range(bigram_index))\n",
    "        end_idx = start_idx + len(target_bigram[0]) + 1 + len(target_bigram[1])\n",
    "        return start_idx, end_idx\n",
    "    except ValueError:\n",
    "        return None, None\n",
    "\n",
    "# Function to compute AUC for a specific span\n",
    "def compute_auc(start_idx, end_idx, saliency_map):\n",
    "    return np.sum(saliency_map[start_idx:end_idx])\n",
    "\n",
    "# Function to evaluate saliency distributions dynamically\n",
    "def evaluate_saliency_distribution_dynamic(inference, texts_data, forward, params, alphabet, vocab_char_size, vocab_word_size, region_map, threshold_ratio=0.1):\n",
    "    overall_results = {}\n",
    "\n",
    "    for text_id, data in texts_data.items():\n",
    "        text = data[\"text\"]\n",
    "        target_bigrams = data[\"target_bigrams\"]\n",
    "\n",
    "        attribution_results = inference.attribute(\n",
    "            text=text,\n",
    "            forward=forward,\n",
    "            params=params,\n",
    "            alphabet=alphabet,\n",
    "            vocab_char_size=vocab_char_size,\n",
    "            vocab_word_size=vocab_word_size,\n",
    "            region_map=region_map\n",
    "        )\n",
    "        saliency_map = np.array(attribution_results.date_saliency)\n",
    "        total_saliency = np.sum(saliency_map)\n",
    "\n",
    "        bigram_results = []\n",
    "\n",
    "        for bigram in target_bigrams:\n",
    "            start_idx, end_idx = find_bigram_indices(text, bigram)\n",
    "            if start_idx is None or end_idx is None:\n",
    "                continue\n",
    "\n",
    "            bigram_auc = compute_auc(start_idx, end_idx, saliency_map)\n",
    "            overlap_saliency = bigram_auc / (total_saliency + 1e-10)\n",
    "            top_peak_within = np.argmax(saliency_map) in range(start_idx, end_idx)\n",
    "\n",
    "            bigram_results.append({\n",
    "                \"bigram\": bigram,\n",
    "                \"bigram_auc\": bigram_auc,\n",
    "                \"total_saliency\": total_saliency,\n",
    "                \"overlap_saliency\": overlap_saliency,\n",
    "                \"top_peak_within\": top_peak_within,\n",
    "            })\n",
    "\n",
    "        auc_values = [result[\"bigram_auc\"] for result in bigram_results]\n",
    "        ranks = rankdata(-np.array(auc_values), method=\"min\")\n",
    "\n",
    "        ranked_results = [\n",
    "            {**result, \"rank\": rank}\n",
    "            for result, rank in zip(bigram_results, ranks)\n",
    "        ]\n",
    "        ranked_results = sorted(ranked_results, key=lambda x: x[\"rank\"])\n",
    "\n",
    "        relevant_indices = [idx for idx, result in enumerate(ranked_results) if result[\"overlap_saliency\"] > threshold_ratio]\n",
    "\n",
    "        mrr = sum(1 / (ranked_results[idx][\"rank\"] + 1) for idx in relevant_indices) / len(target_bigrams) if target_bigrams else 0\n",
    "        average_precision = np.mean([(i + 1) / (ranked_results[idx][\"rank\"] + 1) for i, idx in enumerate(relevant_indices)]) if relevant_indices else 0\n",
    "        ndcg = sum(1 / np.log2(ranked_results[idx][\"rank\"] + 2) for idx in relevant_indices) / len(target_bigrams) if target_bigrams else 0\n",
    "\n",
    "        overall_results[text_id] = {\n",
    "            \"bigram_results\": ranked_results,\n",
    "            \"mrr\": mrr,\n",
    "            \"average_precision\": average_precision,\n",
    "            \"ndcg\": ndcg,\n",
    "        }\n",
    "\n",
    "    return overall_results\n",
    "\n",
    "# Function to aggregate global metrics across all inscriptions\n",
    "def aggregate_global_metrics(results):\n",
    "    total_mrr = 0\n",
    "    total_map = 0\n",
    "    total_ndcg = 0\n",
    "    total_bigrams = 0\n",
    "\n",
    "    for text_id, result in results.items():\n",
    "        total_mrr += result[\"mrr\"]\n",
    "        total_map += result[\"average_precision\"]\n",
    "        total_ndcg += result[\"ndcg\"]\n",
    "        total_bigrams += len(result[\"bigram_results\"])\n",
    "\n",
    "    avg_mrr = total_mrr / len(results)\n",
    "    avg_map = total_map / len(results)\n",
    "    avg_ndcg = total_ndcg / len(results)\n",
    "\n",
    "    return {\n",
    "        \"Average MRR\": avg_mrr,\n",
    "        \"Average MAP\": avg_map,\n",
    "        \"Average NDCG\": avg_ndcg,\n",
    "        \"Total Bigrams Evaluated\": total_bigrams,\n",
    "    }\n",
    "\n",
    "# Function to aggregate AUC and overlap statistics\n",
    "def aggregate_bigram_stats(results):\n",
    "    all_auc_values = []\n",
    "    all_overlap_saliency = []\n",
    "\n",
    "    for result in results.values():\n",
    "        for bigram_result in result[\"bigram_results\"]:\n",
    "            all_auc_values.append(bigram_result[\"bigram_auc\"])\n",
    "            all_overlap_saliency.append(bigram_result[\"overlap_saliency\"])\n",
    "\n",
    "    mean_auc = np.mean(all_auc_values)\n",
    "    median_auc = np.median(all_auc_values)\n",
    "    std_auc = np.std(all_auc_values)\n",
    "    mean_overlap = np.mean(all_overlap_saliency)\n",
    "    median_overlap = np.median(all_overlap_saliency)\n",
    "\n",
    "    return {\n",
    "        \"Mean AUC\": mean_auc,\n",
    "        \"Median AUC\": median_auc,\n",
    "        \"AUC Std Dev\": std_auc,\n",
    "        \"Mean Overlap Saliency\": mean_overlap,\n",
    "        \"Median Overlap Saliency\": median_overlap,\n",
    "        \"Total Bigrams\": len(all_auc_values),\n",
    "    }\n",
    "\n",
    "# Function to plot AUC distribution\n",
    "def plot_auc_distribution(auc_values):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(auc_values, bins=20, color=\"#69b3a2\", edgecolor=\"black\", alpha=0.7)\n",
    "    plt.title(\"AUC Distribution Across All Bigrams\")\n",
    "    plt.xlabel(\"AUC Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot overlap distribution\n",
    "def plot_overlap_distribution(overlap_values):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(overlap_values, bins=20, color=\"#ffa07a\", edgecolor=\"black\", alpha=0.7)\n",
    "    plt.title(\"Overlap Saliency Distribution Across All Bigrams\")\n",
    "    plt.xlabel(\"Overlap Saliency\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_saliency_distribution_dynamic(\n",
    "    inference=inference,\n",
    "    texts_data=texts_data,\n",
    "    forward=forward,\n",
    "    params=params,\n",
    "    alphabet=alphabet,\n",
    "    vocab_char_size=vocab_char_size,\n",
    "    vocab_word_size=vocab_word_size,\n",
    "    region_map=region_map\n",
    ")\n",
    "\n",
    "# Aggregate method-level statistics\n",
    "global_metrics = aggregate_global_metrics(results)\n",
    "bigram_stats = aggregate_bigram_stats(results)\n",
    "\n",
    "# Print overall results\n",
    "print(\"\\n### Method-Level Evaluation Metrics ###\")\n",
    "for metric, value in global_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n### Bigram-Level AUC and Overlap Statistics ###\")\n",
    "for metric, value in bigram_stats.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Visualize distributions\n",
    "all_auc_values = [bigram_result[\"bigram_auc\"] for result in results.values() for bigram_result in result[\"bigram_results\"]]\n",
    "all_overlap_values = [bigram_result[\"overlap_saliency\"] for result in results.values() for bigram_result in result[\"bigram_results\"]]\n",
    "\n",
    "plot_auc_distribution(all_auc_values)\n",
    "plot_overlap_distribution(all_overlap_values)\n",
    "\n",
    "\n",
    "#MRR: Εστιάζει μόνο στην πρώτη σωστή πρόβλεψη. Αν είναι μηδέν, σημαίνει ότι το σύστημα δεν εντόπισε κανένα σωστό bigram.\n",
    "#MAP: Λαμβάνει υπόψη όλα τα σωστά bigrams, αλλά απαιτεί να είναι σωστά ταξινομημένα.\n",
    "#NDCG: Είναι πιο ανεκτικό από το MAP, καθώς επιτρέπει στα σωστά bigrams να βρίσκονται και σε χαμηλότερες θέσεις, με μικρότερη \"ποινή\".\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
